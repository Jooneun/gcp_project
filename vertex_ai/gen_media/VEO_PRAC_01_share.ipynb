{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293ce176-79b6-40cf-9f15-feedacae644e",
   "metadata": {},
   "source": [
    "# CE Enablement Session - Practice 01\n",
    "- ## Workflow: IMG --> Nano --> VEO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b321977-2b38-4d94-b06c-9e6deb32177d",
   "metadata": {},
   "source": [
    "### 1. (권장) 가상환경 생성 및 활성화\n",
    "python -m venv venv\n",
    "#### macOS/Linux:\n",
    "source venv/bin/activate\n",
    "\n",
    "#### 2. 필수 파이썬 라이브러리 설치\n",
    "pip install --upgrade google-cloud-aiplatform Pillow ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1a7540-ea61-411a-9109-7156d86ff26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GenAI 클라이언트가 성공적으로 초기화되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. 패키지 임포트 및 전역 설정\n",
    "# ==============================================================================\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import mimetypes\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "# Third-party libraries\n",
    "import requests\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "# Google Cloud and Generative AI libraries\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import (\n",
    "    EditImageConfig,\n",
    "    GenerateImagesConfig,\n",
    "    Image,\n",
    "    MaskReferenceConfig,\n",
    "    MaskReferenceImage,\n",
    "    RawReferenceImage,\n",
    ")\n",
    "\n",
    "# IPython display for notebooks\n",
    "from IPython.display import display\n",
    "\n",
    "# --- 전역 상수 정의 ---\n",
    "# 'jc-gcp-project'를 당신의 GCP 프로젝트 ID로 변경해주세요.\n",
    "PROJECT_ID = \"jc-gcp-project\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "OUTPUT_DIR = \"veo_story_telling\"\n",
    "\n",
    "# --- 전역 변수 및 초기화 ---\n",
    "# 스크립트 시작 시 출력 디렉토리 생성\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# API 클라이언트를 스크립트 시작 시 한 번만 초기화하여 모든 함수에서 재사용합니다.\n",
    "# 이렇게 하면 반복적인 인증 및 객체 생성 오버헤드가 사라집니다.\n",
    "try:\n",
    "    CLIENT = genai.Client(vertexai=True, project=PROJECT_ID, location=\"global\")\n",
    "    print(\"✅ GenAI 클라이언트가 성공적으로 초기화되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ GenAI 클라이언트 초기화 실패: {e}\")\n",
    "    CLIENT = None\n",
    "\n",
    "# VEO 비디오 생성을 위한 Image 데이터 클래스\n",
    "# 함수 외부로 이동하여 반복적인 클래스 정의를 방지합니다.\n",
    "class VeoImage:\n",
    "    \"\"\"VEO API에 이미지 데이터를 전달하기 위한 간단한 데이터 클래스입니다.\"\"\"\n",
    "    def __init__(self, gcs_uri=None, image_bytes=None, mime_type=None):\n",
    "        self.gcs_uri = gcs_uri\n",
    "        self.image_bytes = image_bytes\n",
    "        self.mime_type = mime_type\n",
    "\n",
    "    def __repr__(self):\n",
    "        bytes_repr = str(self.image_bytes[:60]) + '...' if self.image_bytes else None\n",
    "        return (f\"VeoImage(gcs_uri={self.gcs_uri}, \"\n",
    "                f\"mime_type='{self.mime_type}', \"\n",
    "                f\"image_bytes={bytes_repr})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb34ee7-853e-4607-9184-46c5549dda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. 헬퍼 함수 (Helper Functions)\n",
    "# ==============================================================================\n",
    "\n",
    "def _load_image_part(path: str) -> Optional[types.Part]:\n",
    "    \"\"\"\n",
    "    로컬 경로 또는 GCS URI에서 이미지를 로드하여 genai.types.Part 객체로 반환합니다.\n",
    "    이 함수는 코드 중복을 방지하기 위해 사용됩니다.\n",
    "    \"\"\"\n",
    "    if path.startswith(\"gs://\"):\n",
    "        mime_type, _ = mimetypes.guess_type(path)\n",
    "        if not mime_type:\n",
    "            mime_type = \"image/jpeg\"  # GCS 기본값\n",
    "        print(f\"✅ GCS 이미지 로드: {path}\")\n",
    "        return types.Part.from_uri(file_uri=path, mime_type=mime_type)\n",
    "    else:\n",
    "        try:\n",
    "            mime_type, _ = mimetypes.guess_type(path)\n",
    "            if not mime_type:\n",
    "                raise IOError(f\"파일의 MIME 타입을 확인할 수 없습니다: {path}\")\n",
    "            \n",
    "            with open(path, \"rb\") as f:\n",
    "                image_bytes = f.read()\n",
    "            \n",
    "            print(f\"✅ 로컬 이미지 로드: {path}\")\n",
    "            return types.Part.from_bytes(data=image_bytes, mime_type=mime_type)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ 오류: 로컬 파일 '{path}'를 찾을 수 없습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류: 로컬 파일 '{path}' 처리 중 문제 발생: {type(e).__name__} - {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d188ef-aaaf-4c81-89b1-bb71b7c0a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. 핵심 생성 함수 (Core Generative Functions)\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_prompt_from_images(user_prompt: str, image_paths: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    사용자 프롬프트와 이미지를 기반으로 광고에 최적화된 새로운 프롬프트를 생성합니다.\n",
    "    \"\"\"\n",
    "    if not CLIENT:\n",
    "        print(\"오류: GenAI 클라이언트가 초기화되지 않았습니다.\")\n",
    "        return None\n",
    "    if not image_paths:\n",
    "        print(\"오류: 하나 이상의 이미지 파일 경로를 제공해야 합니다.\")\n",
    "        return None\n",
    "    if len(image_paths) > 2:\n",
    "        print(\"경고: 최대 2개의 이미지만 처리됩니다. 처음 2개의 이미지를 사용합니다.\")\n",
    "        image_paths = image_paths[:2]\n",
    "\n",
    "    try:\n",
    "        default_prompt = \"\"\"\n",
    "        You will receive a photo and a user prompt. Your task is to analyze both and generate a detailed and specific prompt that enhances the quality and relevance of the advertisement, **while explicitly prioritizing the preservation of existing subjects and objects in the original image.**\n",
    "\n",
    "        For example, if the user asks to composite a person into a photo, analyze the photo to suggest appropriate poses for the person that *integrate seamlessly with the existing scene*. If the user asks to change the text on a poster, create a prompt that ensures the new text blends seamlessly with the original design *without altering the original visual elements unnecessarily*.\n",
    "\n",
    "        The goal is to enhance the advertisement by subtly modifying or adding elements that complement the original, rather than replacing or heavily altering it.\n",
    "\n",
    "        Example Output:\"Enhance the existing image by subtly adjusting the lighting to highlight the cosmetic product, ensuring the woman's pose and expression remain the same but are visually optimized for the product's branding and target audience. Do not alter the woman's appearance or the product's original form.\"        \n",
    "       \n",
    "        The customer request is : \n",
    "        \"\"\"\n",
    "        parts = [types.Part.from_text(text=default_prompt), types.Part.from_text(text=user_prompt)]\n",
    "\n",
    "        for path in image_paths:\n",
    "            image_part = _load_image_part(path)\n",
    "            if image_part:\n",
    "                parts.append(image_part)\n",
    "\n",
    "        system_instruction_text = \"\"\"\n",
    "        You are a prompt expert specializing in advertising. Your task is to take a photo and a user prompt as input and generate a refined prompt that is optimized for creating effective advertisements.\n",
    "        \"\"\"\n",
    "\n",
    "        model = \"gemini-2.5-flash\"\n",
    "        contents = [types.Content(role=\"user\", parts=parts)]\n",
    "\n",
    "        generate_content_config = types.GenerateContentConfig(\n",
    "            temperature=1, top_p=1, seed=0, max_output_tokens=8192,\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(category=c, threshold=\"BLOCK_NONE\") for c in\n",
    "                [\"HARM_CATEGORY_HATE_SPEECH\", \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_HARASSMENT\"]\n",
    "            ],\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema={\"type\": \"OBJECT\", \"properties\": {\"response\": {\"type\": \"STRING\"}}},\n",
    "            system_instruction=[types.Part.from_text(text=system_instruction_text)],\n",
    "        )\n",
    "        \n",
    "        print(\"\\n생성 중...\")\n",
    "        response = CLIENT.models.generate_content(\n",
    "            model=model, contents=contents, config=generate_content_config\n",
    "        )\n",
    "        print(\"생성 완료.\")\n",
    "        \n",
    "        try:\n",
    "            parsed_json = json.loads(response.text)\n",
    "            return parsed_json.get('response')\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"❌ 오류: API 응답을 JSON으로 파싱할 수 없습니다. 원본 응답: {response.text}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류가 발생했습니다: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_edited_image(prompt: str, image_paths: List[str], save_image: bool = True, output_path: Optional[str] = None) -> tuple[Optional[bytes], Optional[str]]:\n",
    "    \"\"\"\n",
    "    이미지를 생성하고, 텍스트만 반환될 경우 지능적으로 재시도하여 결과물을 파일로 저장합니다.\n",
    "    \"\"\"\n",
    "    if not CLIENT:\n",
    "        print(\"오류: GenAI 클라이언트가 초기화되지 않았습니다.\")\n",
    "        return None, None\n",
    "\n",
    "    user_parts = []\n",
    "    for path in image_paths:\n",
    "        image_part = _load_image_part(path)\n",
    "        if image_part:\n",
    "            user_parts.append(image_part)\n",
    "    \n",
    "    user_parts.append(types.Part.from_text(text=prompt))\n",
    "    initial_contents = [types.Content(role=\"user\", parts=user_parts)]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1, top_p=0.95, max_output_tokens=32768,\n",
    "        response_modalities=[\"TEXT\", \"IMAGE\"],\n",
    "        safety_settings=[\n",
    "            types.SafetySetting(category=c, threshold=\"BLOCK_NONE\") for c in\n",
    "            [\"HARM_CATEGORY_HATE_SPEECH\", \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_HARASSMENT\"]\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    image_found = False\n",
    "    model_response_text = \"\"\n",
    "    received_image_bytes = b\"\"\n",
    "    final_path = None\n",
    "\n",
    "    def process_stream_response(current_contents):\n",
    "        nonlocal image_found, model_response_text, received_image_bytes, final_path\n",
    "        \n",
    "        for chunk in CLIENT.models.generate_content_stream(\n",
    "            model=\"gemini-2.5-flash-image-preview\", contents=current_contents, config=generate_content_config,\n",
    "        ):\n",
    "            for part in chunk.candidates[0].content.parts:\n",
    "                if part.text:\n",
    "                    model_response_text += part.text\n",
    "                    print(part.text, end=\"\")\n",
    "                \n",
    "                if part.inline_data:\n",
    "                    image_found = True\n",
    "                    received_image_bytes = part.inline_data.data\n",
    "                    print(\"\\n\\n--- ✅ 이미지 수신 완료 ---\")\n",
    "                    \n",
    "                    if save_image:\n",
    "                        if output_path:\n",
    "                            final_path = output_path\n",
    "                        else:\n",
    "                            default_dir = os.path.join(OUTPUT_DIR, \"sample_imgs\")\n",
    "                            os.makedirs(default_dir, exist_ok=True)\n",
    "                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                            filename = f\"output_{timestamp}.png\"\n",
    "                            final_path = os.path.join(default_dir, filename)\n",
    "                        \n",
    "                        try:\n",
    "                            with open(final_path, \"wb\") as f:\n",
    "                                f.write(received_image_bytes)\n",
    "                            print(f\"💾 이미지가 '{os.path.abspath(final_path)}' 파일로 저장되었습니다.\")\n",
    "                        except IOError as e:\n",
    "                            print(f\"❌ 파일 저장 중 오류 발생: {e}\")\n",
    "    \n",
    "    print(f\"--- 1차 이미지 생성 시도 (입력 이미지 {len(image_paths)}개) ---\")\n",
    "    process_stream_response(initial_contents)\n",
    "    \n",
    "    if not image_found:\n",
    "        print(\"\\n\\n--- ⚠️ 1차 시도에서 이미지가 생성되지 않았습니다. 2차 시도를 시작합니다. ---\")\n",
    "        \n",
    "        retry_contents = list(initial_contents)\n",
    "        retry_contents.append(types.Content(role=\"model\", parts=[types.Part.from_text(text=model_response_text)]))\n",
    "        retry_contents.append(types.Content(role=\"user\", parts=[types.Part.from_text(text=\"네, 좋습니다. 어떤 방법을 추가해서라도 이미지를 생성해 주세요.\")]))\n",
    "\n",
    "        image_found = False\n",
    "        model_response_text = \"\"\n",
    "        received_image_bytes = b\"\"\n",
    "\n",
    "        process_stream_response(retry_contents)\n",
    "        print(\"\\n\\n--- ✅ 2차 시도 완료 ---\")\n",
    "\n",
    "    if not image_found:\n",
    "        print(\"\\n\\n--- ❌ 최종적으로 이미지 생성에 실패했습니다. ---\")\n",
    "    \n",
    "    return received_image_bytes, final_path\n",
    "\n",
    "\n",
    "def generate_video_from_image(image_path: str, scene_story: str, scene_idx: int) -> str:\n",
    "    \"\"\"\n",
    "    단일 이미지와 스토리 프롬프트를 기반으로 비디오를 생성합니다.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    if not CLIENT:\n",
    "        print(\"오류: GenAI 클라이언트가 초기화되지 않았습니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        mime_type, _ = mimetypes.guess_type(image_path)\n",
    "        if not mime_type:\n",
    "            raise ValueError(f\"Could not determine MIME type for {image_path}\")\n",
    "\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_byte_data = image_file.read()\n",
    "\n",
    "        image_instance = VeoImage(\n",
    "            image_bytes=image_byte_data,\n",
    "            mime_type=mime_type\n",
    "        )\n",
    "        print(\"✅ VeoImage 객체가 성공적으로 생성되었습니다!\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: 파일을 찾을 수 없습니다 '{image_path}'\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate a video from this image that shows: {scene_story}\n",
    "    The video should be smooth and cinematic, lasting 8 seconds.\n",
    "    Create natural movement and progression from the starting image.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        operation = CLIENT.models.generate_videos(\n",
    "            model=\"veo-3.0-generate-preview\",\n",
    "            prompt=prompt,\n",
    "            image=image_instance,\n",
    "        )\n",
    "\n",
    "        while not operation.done:\n",
    "            print(\"비디오 생성 완료를 기다리는 중...\")\n",
    "            time.sleep(10)\n",
    "            operation = CLIENT.operations.get(operation)\n",
    "\n",
    "        if operation.done and not operation.error:\n",
    "            video_bytes = operation.response.generated_videos[0].video.video_bytes\n",
    "            video_path = f\"{OUTPUT_DIR}/scene_{scene_idx}_video.mp4\"\n",
    "            with open(video_path, 'wb') as f:\n",
    "                f.write(video_bytes)\n",
    "            print(f\"'{video_path}' 파일로 비디오를 성공적으로 저장했습니다.\")\n",
    "            return video_path\n",
    "        else:\n",
    "            print(\"비디오 생성 작업이 성공적으로 완료되지 않았습니다.\")\n",
    "            if operation.error:\n",
    "                print(f\"오류: {operation.error}\")\n",
    "            return \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 비디오 생성 중 오류 발생: {e}\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d994864-14c1-4862-a0e0-9c7039cb5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. 이미지 편집/아웃페인팅 함수\n",
    "# ==============================================================================\n",
    "\n",
    "def get_bytes_from_pil(image: PIL_Image.Image) -> bytes:\n",
    "    \"\"\"PIL 이미지를 PNG 바이트로 변환합니다.\"\"\"\n",
    "    byte_io_png = io.BytesIO()\n",
    "    image.save(byte_io_png, \"PNG\")\n",
    "    return byte_io_png.getvalue()\n",
    "\n",
    "def pad_to_target_size(source_image, target_size=(1536, 1536), mode=\"RGB\", vertical_offset_ratio=0, horizontal_offset_ratio=0, fill_val=255):\n",
    "    \"\"\"아웃페인팅을 위해 이미지를 특정 크기로 패딩합니다.\"\"\"\n",
    "    orig_w, orig_h = source_image.size\n",
    "    target_w, target_h = target_size\n",
    "    \n",
    "    insert_x = int((target_w - orig_w) / 2 + horizontal_offset_ratio * target_w)\n",
    "    insert_y = int((target_h - orig_h) / 2 + vertical_offset_ratio * target_h)\n",
    "    insert_x = min(max(0, insert_x), target_w - orig_w)\n",
    "    insert_y = min(max(0, insert_y), target_h - orig_h)\n",
    "    \n",
    "    color = (fill_val, fill_val, fill_val) if mode == \"RGB\" else fill_val\n",
    "    padded_image = PIL_Image.new(mode, target_size, color=color)\n",
    "    padded_image.paste(source_image, (insert_x, insert_y))\n",
    "    return padded_image\n",
    "\n",
    "def pad_image_and_mask(image_pil, mask_pil, target_size, v_offset, h_offset):\n",
    "    \"\"\"이미지와 마스크를 대상 크기에 맞게 조정하고 패딩합니다.\"\"\"\n",
    "    image_pil.thumbnail(target_size)\n",
    "    mask_pil.thumbnail(target_size)\n",
    "    \n",
    "    image_pil = pad_to_target_size(image_pil, target_size, \"RGB\", v_offset, h_offset, 0)\n",
    "    mask_pil = pad_to_target_size(mask_pil, target_size, \"L\", v_offset, h_offset, 255)\n",
    "    return image_pil, mask_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969715de-3cbc-40da-b635-d4a0303c063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. 메인 실행 로직\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e39ca2-65fd-4084-b6fc-977071f1c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 🚀 1단계: 광고 카피용 프롬프트 생성 ---\n",
      "✅ 로컬 이미지 로드: veo_story_telling/sample_imgs/two_people_ads.png\n",
      "\n",
      "생성 중...\n",
      "생성 완료.\n",
      "Identify the Korean text \"부드러움과 감각적인 향 어노브로 완성하는 대담한 우아함\" in the image. Replace this specific Korean text with the English phrase \"A bold elegance perfected with soft and sensual ANOVE fragrance.\". Ensure that all other elements of the original image, including the models, background, lighting, and the existing English text \"UNLEASH YOUR\" and \"Bold Elegance\", remain completely unchanged. The new English text should seamlessly adopt the font style, color, size, and spatial alignment of the original Korean text to maintain visual consistency.\n"
     ]
    }
   ],
   "source": [
    "# --- 1단계: 프롬프트 생성 ---\n",
    "print(\"--- 🚀 1단계: 광고 카피용 프롬프트 생성 ---\")\n",
    "prompt_text = \"광고 이미지 속 한글을 잘 어울리는 영어로 변경하고 싶어.\"\n",
    "image_files = [\"veo_story_telling/sample_imgs/two_people_ads.png\"]\n",
    "# 생성된 프롬프트를 변수에 저장\n",
    "generated_prompt = generate_prompt_from_images(user_prompt=prompt_text, image_paths=image_files)\n",
    "print(generated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6cdd0c-8126-4a90-916f-c0b20b41963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 1단계: 프롬프트 생성 ---\n",
    "# print(\"--- 🚀 1단계: 광고 카피용 프롬프트 생성 ---\")\n",
    "# prompt_text = \"첫번째 사진 속 모델이 두번째 제품을 광고하는 사진으로 만들고 싶어. 최대한 자연스럽게 제품 사용하는 것처럼 만들고, 이미지속 글자는지워\"\n",
    "# image_files = [\"veo_story_telling/sample_imgs/rose.png\", \"veo_story_telling/sample_imgs/product_02_cosme.png\"]\n",
    "# # 생성된 프롬프트를 변수에 저장\n",
    "# generated_prompt = generate_prompt_from_images(user_prompt=prompt_text, image_paths=image_files)\n",
    "# print(generated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2eca70-66af-4f0f-9310-911f1cc44baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2단계: 이미지 편집 ---\n",
    "print(\"\\n--- 🚀 2단계: 생성된 프롬프트를 사용하여 이미지 편집 ---\")\n",
    "edited_image_bytes, edited_image_path = generate_edited_image(\n",
    "    prompt=generated_prompt,\n",
    "    image_paths=image_files\n",
    ")\n",
    "\n",
    "print(\"\\n--- ✅ 편집된 이미지 ---\")\n",
    "display(PIL_Image.open(io.BytesIO(edited_image_bytes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94b73c-13ef-4caa-aeb0-398f0dd5f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3단계: 아웃페인팅 ---\n",
    "print(\"\\n--- 🚀 3단계: 편집된 이미지 16:9 비율로 아웃페인팅 ---\")\n",
    "\n",
    "initial_image_pil = PIL_Image.open(edited_image_path)\n",
    "mask_pil = PIL_Image.new(\"L\", initial_image_pil.size, 0)\n",
    "\n",
    "image_height = 500\n",
    "image_width = int(image_height * 16 / 9)\n",
    "target_size = (image_width, image_height)\n",
    "\n",
    "image_pil_outpaint, mask_pil_outpaint = pad_image_and_mask(\n",
    "    initial_image_pil, mask_pil, target_size, 0, 0\n",
    ")\n",
    "\n",
    "image_pil_outpaint_image = Image(image_bytes=get_bytes_from_pil(image_pil_outpaint))\n",
    "mask_pil_outpaint_image = Image(image_bytes=get_bytes_from_pil(mask_pil_outpaint))\n",
    "\n",
    "raw_ref_image = RawReferenceImage(reference_image=image_pil_outpaint_image, reference_id=0)\n",
    "mask_ref_image = MaskReferenceImage(\n",
    "    reference_id=1,\n",
    "    reference_image=mask_pil_outpaint_image,\n",
    "    config=MaskReferenceConfig(mask_mode=\"MASK_MODE_USER_PROVIDED\", mask_dilation=0.03),\n",
    ")\n",
    "\n",
    "outpaint_prompt = \"\"\"\n",
    "This image is a crop of a much larger photograph.\n",
    "Reveal the rest of the original scene.\n",
    "Extend the environment naturally, maintaining the exact same lighting, mood, and fine details as the provided image.\n",
    "\"\"\"\n",
    "outpainted_result = CLIENT.models.edit_image(\n",
    "    model=\"imagen-3.0-capability-001\",\n",
    "    prompt=outpaint_prompt,\n",
    "    reference_images=[raw_ref_image, mask_ref_image],\n",
    "    config=EditImageConfig(\n",
    "        edit_mode=\"EDIT_MODE_OUTPAINT\", number_of_images=1,\n",
    "        safety_filter_level=\"BLOCK_MEDIUM_AND_ABOVE\", person_generation=\"ALLOW_ADULT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "generated_image_bytes = outpainted_result.generated_images[0].image.image_bytes\n",
    "output_filename = os.path.join(OUTPUT_DIR, \"sample_imgs\", \"edited_image_result.png\")\n",
    "\n",
    "with open(output_filename, \"wb\") as f:\n",
    "    f.write(generated_image_bytes)\n",
    "print(f\"✅ 아웃페인팅 이미지가 '{output_filename}' 파일로 저장되었습니다.\")\n",
    "\n",
    "print(\"\\n--- ✅ 아웃페인팅 결과 이미지 ---\")\n",
    "display(PIL_Image.open(io.BytesIO(generated_image_bytes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4df6f9b-a6fa-47e0-8822-b5e5d805816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ VeoImage 객체가 성공적으로 생성되었습니다!\n",
      "비디오 생성 완료를 기다리는 중...\n",
      "비디오 생성 완료를 기다리는 중...\n",
      "비디오 생성 완료를 기다리는 중...\n",
      "비디오 생성 완료를 기다리는 중...\n",
      "비디오 생성 완료를 기다리는 중...\n",
      "비디오 생성 완료를 기다리는 중...\n",
      "'veo_story_telling/scene_1_video.mp4' 파일로 비디오를 성공적으로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "input_img_file = \"veo_story_telling/sample_imgs/edited_image_result.png\"\n",
    "veo_prompt = \"사진속 두 모델이 자연스러운 포즈를 취하는 영상\"\n",
    "\n",
    "vid_result = generate_video_from_image(input_img_file, veo_prompt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575989a-a8ad-4f60-8151-3adb08c0d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_img_file = \"veo_story_telling/sample_imgs/edited_image_result.png\"\n",
    "# veo_prompt = \"화장품을 광고하기 위해 팔에 문지르는 영상\"\n",
    "\n",
    "# vid_result = generate_video_from_image(input_img_file, veo_prompt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d09041-83a5-4bb9-97dc-779f6cadc2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-myenv-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
