{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760498c0-337a-44ed-9b3a-1d636e0a9103",
   "metadata": {},
   "source": [
    "## CE Enablement Session - Practice 03\n",
    "- ## Workflow: Story telling: Gemini --> VEO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8adc03-57ed-4a76-90e9-086d9c770fd8",
   "metadata": {},
   "source": [
    "### 1. (ê¶Œì¥) ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”\n",
    "python -m venv venv\n",
    "#### macOS/Linux:\n",
    "source venv/bin/activate\n",
    "\n",
    "#### 2. í•„ìˆ˜ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "pip install --upgrade google-cloud-aiplatform google-cloud-texttospeech moviepy Pillow requests ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861603e4-0deb-4efd-af8c-ee163a5d68f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ë° ì „ì—­ ì„¤ì •\n",
    "# ==============================================================================\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import mimetypes\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Third-party libraries\n",
    "import requests\n",
    "from PIL import Image as PIL_Image  # 'Image' ì´ë¦„ ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ 'PIL_Image'ë¡œ ë³„ì¹­ ì§€ì •\n",
    "from moviepy.editor import (\n",
    "    VideoFileClip, AudioFileClip, CompositeVideoClip,\n",
    "    concatenate_videoclips, ImageClip, CompositeAudioClip\n",
    ")\n",
    "from moviepy.video.fx.all import speedx\n",
    "from moviepy.audio.fx.all import audio_loop\n",
    "\n",
    "# Google Cloud and Generative AI libraries\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "from google.cloud import texttospeech\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import (\n",
    "    EditImageConfig,\n",
    "    GenerateImagesConfig,\n",
    "    Image,\n",
    "    MaskReferenceConfig,\n",
    "    MaskReferenceImage,\n",
    "    RawReferenceImage,\n",
    ")\n",
    "from IPython.display import Audio # Jupyter/Colab í™˜ê²½ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒìš©\n",
    "\n",
    "# --- ì „ì—­ ìƒìˆ˜ ì •ì˜ ---\n",
    "PROJECT_ID = \"jc-gcp-project\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "OUTPUT_DIR = \"veo_story_telling\"\n",
    "LYRIA_ENDPOINT_URL = (\n",
    "    f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}\"\n",
    "    \"/locations/us-central1/publishers/google/models/lyria-002:predict\"\n",
    ")\n",
    "\n",
    "# --- ì „ì—­ ë³€ìˆ˜ ë° ì´ˆê¸°í™” ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ì—¬ ëª¨ë“  í•¨ìˆ˜ì—ì„œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    CLIENT = genai.Client(vertexai=True, project=PROJECT_ID, location=\"global\")\n",
    "    print(\"âœ… GenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ GenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    CLIENT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9564ecb-c949-45a7-a29c-4b3a211f1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. í—¬í¼ í•¨ìˆ˜ (Helper Functions)\n",
    "# ==============================================================================\n",
    "\n",
    "def _send_lyria_request(data=None) -> dict:\n",
    "    \"\"\"Lyria (ìŒì•… ìƒì„±) APIì— ìš”ì²­ì„ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    creds, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {creds.token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    response = requests.post(LYRIA_ENDPOINT_URL, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def _poll_and_save_video(operation: any, scene_idx: int) -> str:\n",
    "    \"\"\"VEO ì˜ìƒ ìƒì„±ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ê³  ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    while not operation.done:\n",
    "        print(\"Waiting for video generation/animation to complete...\")\n",
    "        time.sleep(10)\n",
    "        operation = CLIENT.operations.get(operation)\n",
    "\n",
    "    if operation.done and not operation.error and hasattr(operation, 'response') and operation.response.generated_videos:\n",
    "        video_bytes = operation.response.generated_videos[0].video.video_bytes\n",
    "        video_path = f\"{OUTPUT_DIR}/scene_{scene_idx}_video.mp4\"\n",
    "        try:\n",
    "            with open(video_path, 'wb') as f:\n",
    "                f.write(video_bytes)\n",
    "            print(f\"âœ… Video saved successfully to '{video_path}'\")\n",
    "            return video_path\n",
    "        except IOError as e:\n",
    "            raise Exception(f\"Error saving video file for scene {scene_idx}: {e}\")\n",
    "    else:\n",
    "        error_message = f\"Video generation failed for scene {scene_idx}.\"\n",
    "        if hasattr(operation, 'error') and operation.error:\n",
    "            error_message += f\" Reason: {operation.error}\"\n",
    "        else:\n",
    "            error_message += \" Reason: The operation may have been blocked by safety filters or returned no content.\"\n",
    "        raise Exception(error_message)\n",
    "\n",
    "def _send_lyria_request(data=None, max_retries=3) -> dict:\n",
    "    \"\"\"Lyria (ìŒì•… ìƒì„±) APIì— ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•˜ì—¬ ìš”ì²­ì„ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    creds, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            creds.refresh(auth_req)\n",
    "            headers[\"Authorization\"] = f\"Bearer {creds.token}\"\n",
    "            \n",
    "            response = requests.post(LYRIA_ENDPOINT_URL, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"âŒ Lyria API ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}\")\n",
    "            # ì„œë²„ê°€ ë³´ë‚¸ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ë©´ ë””ë²„ê¹…ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "            if e.response is not None:\n",
    "                print(f\"    - ì„œë²„ ì‘ë‹µ: {e.response.text}\")\n",
    "            \n",
    "            if attempt + 1 == max_retries:\n",
    "                print(\"ğŸš¨ ìµœì¢… ì¬ì‹œë„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                raise\n",
    "            \n",
    "            print(f\"    - 5ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    raise Exception(\"API ìš”ì²­ì´ ëª¨ë“  ì¬ì‹œë„ ëì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f069f8-933b-4fb0-b824-e9a954451230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. í•µì‹¬ ìƒì„± í•¨ìˆ˜ (Core Generative Functions)\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_storyline(video_description: str, min_scenes: int = 5, initial_image_path: Optional[str] = None) -> Dict:\n",
    "    \"\"\"1ë‹¨ê³„: ìŠ¤í† ë¦¬ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤. (ìˆ˜ì •ë¨)\"\"\"\n",
    "    print(\"--- 1ë‹¨ê³„: ìŠ¤í† ë¦¬ë¼ì¸ ìƒì„± ì¤‘... ---\")\n",
    "    if not CLIENT:\n",
    "        raise Exception(\"GenAI Client is not initialized.\")\n",
    "\n",
    "    model = \"gemini-2.5-pro\"\n",
    "    parts = []\n",
    "\n",
    "    # --- âœ… ìˆ˜ì •ëœ ë¶€ë¶„: f-stringì„ ì‚¬ìš©í•´ video_descriptionì„ í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ ì‚½ì… ---\n",
    "    prompt = f\"\"\"You are a highly skilled creative content planner. Your primary goal is to fulfill the user's request for a video storyline based on their exact description.\n",
    "\n",
    "    [USER'S VIDEO DESCRIPTION]\n",
    "    {video_description}\n",
    "\n",
    "    Create a compelling storyline for a short, cinematic video based ONLY on the user's description above.\n",
    "    Do not invent a new story that deviates from the user's explicit request.\n",
    "\n",
    "    If an initial image is provided, analyze its mood and style, and integrate them seamlessly into the tone. However, the core narrative MUST come from the [USER'S VIDEO DESCRIPTION].\n",
    "\n",
    "    Your storyline must:\n",
    "    - Directly reflect the [USER'S VIDEO DESCRIPTION].\n",
    "    - Be cinematic, visually engaging, and suitable for a professional video.\n",
    "    - Suggest a music style that complements the story.\n",
    "    - The script should provide appropriate voiceover or dialogue for each scene.\n",
    "    - **Absolutely avoid generating any content that is political, violent, sexually explicit, promotes hate speech, depicts self-harm, involves children in inappropriate contexts, or is otherwise harmful or unethical.**\n",
    "    \"\"\"\n",
    "\n",
    "    if initial_image_path and os.path.exists(initial_image_path):\n",
    "        print(\"--- ì´ˆê¸° ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìŠ¤í† ë¦¬ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤ ---\")\n",
    "        with open(initial_image_path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "        parts.append(types.Part.from_text(text=prompt))\n",
    "        parts.append(types.Part.from_bytes(data=image_bytes, mime_type=\"image/png\"))\n",
    "    else:\n",
    "        print(\"--- í…ìŠ¤íŠ¸ ì„¤ëª…ìœ¼ë¡œ ìŠ¤í† ë¦¬ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤ ---\")\n",
    "        parts.append(types.Part.from_text(text=prompt))\n",
    "\n",
    "    contents = [types.Content(role=\"user\", parts=parts)]\n",
    "    \n",
    "    # (Schema ë° Config ì„¤ì •ì€ ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "    storyline_schema = {\"type\": \"OBJECT\", \"properties\": { \"description\": {\"type\": \"STRING\"}, \"music\": {\"type\": \"STRING\"}, \"scenes\": {\"type\": \"ARRAY\", \"items\": {\"type\": \"OBJECT\", \"properties\": {\"story\": {\"type\": \"STRING\"}, \"script\": {\"type\": \"STRING\"}}}}}}\n",
    "    generate_content_config = types.GenerateContentConfig(temperature=1, top_p=0.95, response_mime_type=\"application/json\", response_schema=storyline_schema, system_instruction=[types.Part.from_text(text=\"Script must be in KOREAN. Music must be in English\")])\n",
    "\n",
    "    response = CLIENT.models.generate_content(model=model, contents=contents, config=generate_content_config)\n",
    "    \n",
    "    clean_text = response.text.strip().removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "    storyline = json.loads(clean_text)\n",
    "    \n",
    "    print(f\"âœ… ìŠ¤í† ë¦¬ë¼ì¸ ìƒì„± ì™„ë£Œ: {len(storyline['scenes'])}ê°œ ì¥ë©´\")\n",
    "    print(storyline)\n",
    "    print()\n",
    "    return storyline\n",
    "\n",
    "def generate_character_sheet(story_description: str) -> str:\n",
    "    \"\"\"ì´ì•¼ê¸° ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ì¸ê³µì˜ ìƒì„¸í•œ ì™¸ëª¨ ì„¤ëª…(ìºë¦­í„° ì‹œíŠ¸)ì„ ìƒì„±í•©ë‹ˆë‹¤. (ìˆ˜ì •ë¨)\"\"\"\n",
    "    print(\"--- ğŸ“ ì£¼ì¸ê³µ ìºë¦­í„° ì‹œíŠ¸ ìƒì„± ì¤‘... ---\")\n",
    "    if not CLIENT:\n",
    "        raise Exception(\"GenAI Client is not initialized.\")\n",
    "        \n",
    "    model = \"gemini-2.5-flash\"\n",
    "    \n",
    "    # --- âœ… ìˆ˜ì •ëœ ë¶€ë¶„: f-stringì„ ì‚¬ìš©í•´ story_descriptionì„ í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ ì‚½ì… ---\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following story summary, create a highly detailed visual description for the main character(s).\n",
    "    This description will be used as a consistent reference for an animation AI.\n",
    "    Describe their physical appearance, clothing, color palette, key features, and overall style.\n",
    "    The description must be detailed enough for any artist to replicate their appearance precisely.\n",
    "    The output should be a single paragraph of text.\n",
    "\n",
    "    [STORY SUMMARY]\n",
    "    {story_description}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = CLIENT.models.generate_content(model=model, contents=prompt)\n",
    "    character_sheet = response.text.strip()\n",
    "    print(f\"âœ… ìºë¦­í„° ì‹œíŠ¸ ìƒì„± ì™„ë£Œ:\\n{character_sheet}\\n\")\n",
    "    return character_sheet\n",
    "\n",
    "def create_detailed_veo_prompt(character_sheet: str, scene_story: str, animation_style: str) -> str:\n",
    "    \"\"\"ìºë¦­í„° ì‹œíŠ¸, ì¥ë©´ ì„¤ëª…, ìŠ¤íƒ€ì¼ì„ ì¡°í•©í•˜ì—¬ VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ìˆ˜ì •ë¨)\"\"\"\n",
    "    print(\"--- ğŸ¤– VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ---\")\n",
    "    if not CLIENT:\n",
    "        raise Exception(\"GenAI Client is not initialized.\")\n",
    "\n",
    "    model = \"gemini-2.5-flash\"\n",
    "\n",
    "    # --- âœ… ìˆ˜ì •ëœ ë¶€ë¶„: f-stringì„ ì‚¬ìš©í•´ ëª¨ë“  ë³€ìˆ˜ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ ì‚½ì… ---\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert animation director. Your task is to combine the following elements into a single, highly detailed, and coherent prompt paragraph for a text-to-video AI (VEO).\n",
    "\n",
    "    1.  **Animation Style (Must adhere to this):** {animation_style}\n",
    "\n",
    "    2.  **Consistent Character Description (Crucial to follow precisely for every detail):** {character_sheet}\n",
    "\n",
    "    3.  **Current Scene Description (The action to portray):** {scene_story}\n",
    "\n",
    "    Combine these into a rich, descriptive paragraph. Explicitly describe the character's appearance based on the character sheet, their actions from the scene story, the camera angle (e.g., close-up, wide shot, point-of-view), the lighting (e.g., dramatic, soft morning light), and the overall mood. The final output must be a single paragraph prompt ready for the video model.\n",
    "    \"\"\"\n",
    "    response = CLIENT.models.generate_content(model=model, contents=prompt)\n",
    "    detailed_prompt = response.text.strip()\n",
    "    print(f\"âœ… ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸:\\n{detailed_prompt}\\n\")\n",
    "    return detailed_prompt\n",
    "\n",
    "def generate_video_from_text(detailed_prompt: str, scene_idx: int) -> str:\n",
    "    \"\"\"ë¯¸ë¦¬ ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ VEO ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"--- ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¡œ Scene {scene_idx+1} ì˜ìƒ ìƒì„± ì¤‘ ---\")\n",
    "    if not CLIENT:\n",
    "        raise Exception(\"GenAI Client is not initialized.\")\n",
    "        \n",
    "    operation = CLIENT.models.generate_videos(model=\"veo-3.0-generate-preview\", prompt=detailed_prompt)\n",
    "    return _poll_and_save_video(operation, scene_idx)\n",
    "\n",
    "def generate_video_from_image(image_path: str, scene_story: str, scene_idx: int) -> str:\n",
    "    \"\"\"ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ì• ë‹ˆë©”ì´ì…˜í™”í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"--- Scene {scene_idx+1} ì´ˆê¸° ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜í™” ì¤‘ ---\")\n",
    "    if not CLIENT:\n",
    "        raise Exception(\"GenAI Client is not initialized.\")\n",
    "\n",
    "    try:\n",
    "        mime_type, _ = mimetypes.guess_type(image_path)\n",
    "        if not mime_type: raise ValueError(f\"Could not determine MIME type for {image_path}\")\n",
    "        with open(image_path, \"rb\") as f: image_byte_data = f.read()\n",
    "        image_part = types.Part.from_bytes(data=image_byte_data, mime_type=mime_type)\n",
    "        print(\"âœ… ì• ë‹ˆë©”ì´ì…˜ìš© ì´ë¯¸ì§€ ê°ì²´ ìƒì„± ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ì´ë¯¸ì§€ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "    prompt = f\"Animate this image. The scene is about: '{scene_story}'... (í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì€ ë™ì¼)\"\n",
    "    operation = CLIENT.models.generate_videos(model=\"veo-3.0-generate-preview\", prompt=prompt, image=image_part)\n",
    "    return _poll_and_save_video(operation, scene_idx)\n",
    "\n",
    "def generate_tts_audio(script: str, scene_idx: int, lang_code: str = \"ko-KR\") -> str:\n",
    "    \"\"\"TTS ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # (ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=script)\n",
    "    voice = texttospeech.VoiceSelectionParams(language_code=lang_code, name=\"ko-KR-Chirp3-HD-Callirrhoe\")\n",
    "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "    response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "    audio_path = f\"{OUTPUT_DIR}/scene_{scene_idx}_audio.mp3\"\n",
    "    with open(audio_path, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "    print(f\"âœ… ì¥ë©´ {scene_idx+1} TTS ìƒì„± ì™„ë£Œ: {audio_path}\")\n",
    "    return audio_path\n",
    "\n",
    "def generate_background_music(music_description: str, duration: float) -> str:\n",
    "    \"\"\"Lyria APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë°°ê²½ìŒì•…ì„ ìƒì„±í•©ë‹ˆë‹¤. (ìš”ì²­ êµ¬ì¡° ì›ë³µ ë° ì¬ì‹œë„ ì ìš©)\"\"\"\n",
    "    print(\"--- ğŸ¼ ë°°ê²½ìŒì•… ìƒì„± ì¤‘... ---\")\n",
    "    \n",
    "    # âœ…âœ…âœ… ìˆ˜ì •ëœ ë¶€ë¶„: ì„±ê³µ ì˜ˆì‹œì— ë§ì¶° ìš”ì²­ êµ¬ì¡°ë¥¼ ì›ë³µí•©ë‹ˆë‹¤. âœ…âœ…âœ…\n",
    "    # duration_secondsê°€ 'instances' ë‚´ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.\n",
    "    music_request = {\n",
    "        \"prompt\": f\"Generate cinematic film score music: {music_description}\",\n",
    "        \"negative_prompt\": \"dark\",\n",
    "        \"sample_count\": 1,\n",
    "        \"duration_seconds\": int(duration)\n",
    "    }\n",
    "    request_data = {\"instances\": [music_request], \"parameters\": {}}\n",
    "    \n",
    "    print(f\"ìš”ì²­ ë°ì´í„°: {request_data}\")\n",
    "    \n",
    "    # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ í—¬í¼ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "    predictions = _send_lyria_request(request_data)[\"predictions\"]\n",
    "    \n",
    "    b64_audio_data = predictions[0]['bytesBase64Encoded']\n",
    "    decoded_audio_data = base64.b64decode(b64_audio_data)\n",
    "    music_path = f\"{OUTPUT_DIR}/background_music.mp3\"\n",
    "    with open(music_path, \"wb\") as out:\n",
    "        out.write(decoded_audio_data)\n",
    "    print(f\"âœ… ë°°ê²½ìŒì•… ìƒì„± ì™„ë£Œ: {music_path}\")\n",
    "    return music_path\n",
    "\n",
    "def combine_video_clips_with_smooth_transitions(video_paths: List[str], audio_paths: List[str], background_music_path: str) -> str:\n",
    "    \"\"\"ìƒì„±ëœ ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, ë°°ê²½ìŒì•…ì„ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # (ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "    video_clips = []\n",
    "    for video_path, audio_path in zip(video_paths, audio_paths):\n",
    "        video_clip = VideoFileClip(video_path)\n",
    "        audio_clip = AudioFileClip(audio_path)\n",
    "        # (ê¸¸ì´ ì¡°ì ˆ ë¡œì§)\n",
    "        if video_clip.duration < audio_clip.duration:\n",
    "            speed_factor = video_clip.duration / audio_clip.duration\n",
    "            video_clip = speedx(video_clip, factor=speed_factor).set_duration(audio_clip.duration)\n",
    "        else:\n",
    "            video_clip = video_clip.subclip(0, audio_clip.duration)\n",
    "        video_with_audio = video_clip.set_audio(audio_clip)\n",
    "        video_clips.append(video_with_audio)\n",
    "    \n",
    "    final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if os.path.exists(background_music_path):\n",
    "        bg_music = AudioFileClip(background_music_path).volumex(0.3)\n",
    "        if bg_music.duration < final_video.duration:\n",
    "            bg_music = audio_loop(bg_music, duration=final_video.duration)\n",
    "        else:\n",
    "            bg_music = bg_music.subclip(0, final_video.duration)\n",
    "        \n",
    "        final_audio = CompositeAudioClip([final_video.audio, bg_music])\n",
    "        final_video.audio = final_audio\n",
    "        \n",
    "    output_path = f\"{OUTPUT_DIR}/final_video_with_continuity.mp4\"\n",
    "    final_video.write_videofile(output_path, codec='libx264', audio_codec='aac', threads=4, preset='medium', logger=None)\n",
    "    print(f\"âœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2281ff-ccbe-46cb-a53b-d548cf67f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ==============================================================================\n",
    "\n",
    "def run_full_pipeline_with_continuity(\n",
    "    video_description: str,\n",
    "    initial_image_path: Optional[str] = None,\n",
    "    lang_code: str = \"ko-KR\",\n",
    "    animation_style: str = \"A vibrant and polished 3D animation in the style of Pixar, with expressive characters and detailed textures.\"\n",
    ") -> Optional[str]:\n",
    "    \n",
    "    print(f\"ğŸš€ Starting pipeline with '{animation_style}' style...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        storyline = generate_storyline(video_description, initial_image_path=initial_image_path)\n",
    "        character_sheet = generate_character_sheet(storyline['description'])\n",
    "        \n",
    "        video_paths = []\n",
    "        audio_paths = []\n",
    "        total_audio_duration = 0\n",
    "        \n",
    "        for idx, scene in enumerate(storyline['scenes']):\n",
    "            print(f\"\\nğŸ¬ Processing Scene {idx + 1}/{len(storyline['scenes'])}...\")\n",
    "            \n",
    "            video_path = \"\"\n",
    "            if idx == 0 and initial_image_path and os.path.exists(initial_image_path):\n",
    "                video_path = generate_video_from_image(initial_image_path, scene['story'], idx)\n",
    "            else:\n",
    "                detailed_prompt = create_detailed_veo_prompt(\n",
    "                    character_sheet=character_sheet,\n",
    "                    scene_story=scene['story'],\n",
    "                    animation_style=animation_style\n",
    "                )\n",
    "                video_path = generate_video_from_text(detailed_prompt, idx)\n",
    "            \n",
    "            video_paths.append(video_path)\n",
    "        \n",
    "            audio_path = generate_tts_audio(scene['script'], idx, lang_code)\n",
    "            audio_paths.append(audio_path)\n",
    "            with AudioFileClip(audio_path) as audio_clip:\n",
    "                total_audio_duration += audio_clip.duration\n",
    "        \n",
    "        background_music_path = generate_background_music(storyline['music'], int(30))\n",
    "        \n",
    "        print(\"\\nğŸï¸ Merging all clips into the final video...\")\n",
    "        final_video_path = combine_video_clips_with_smooth_transitions(video_paths, audio_paths, background_music_path)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nğŸ‰ Pipeline complete! Total time: {elapsed_time:.2f} seconds\")\n",
    "        print(f\"ğŸ“ Final video available at: {final_video_path}\")\n",
    "        \n",
    "        return final_video_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "        print(f\"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79da914-4a49-4929-a9f9-00d0c71e4e3f",
   "metadata": {},
   "source": [
    "## Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee994f1-0dfb-445d-90ce-5cb6ddfe948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting pipeline with 'A vibrant and polished 3D animation in the style of Pixar, with expressive characters and detailed textures.' style...\n",
      "--- 1ë‹¨ê³„: ìŠ¤í† ë¦¬ë¼ì¸ ìƒì„± ì¤‘... ---\n",
      "--- í…ìŠ¤íŠ¸ ì„¤ëª…ìœ¼ë¡œ ìŠ¤í† ë¦¬ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤ ---\n",
      "âœ… ìŠ¤í† ë¦¬ë¼ì¸ ìƒì„± ì™„ë£Œ: 5ê°œ ì¥ë©´\n",
      "{'description': 'í•œ ì Šì€ ê°œë°œìê°€ ê¹Šì€ ë°¤, ë³µì¡í•œ ì½”ë”© ë¬¸ì œì— ë¶€ë”ªíˆì§€ë§Œ, ê·¸ì˜ AI ë™ë°˜ìì™€ í˜‘ë ¥í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  í•¨ê»˜ ì„±ì¥í•˜ëŠ” ê³¼ì •ì„ ê°ì„±ì ì´ê³  ì‹œë„¤ë§ˆí‹±í•˜ê²Œ ë‹´ì•„ë‚¸ ì˜ìƒì…ë‹ˆë‹¤.', 'music': 'Inspiring and uplifting electronic music with a mellow beat', 'scenes': [{'story': 'ì–´ë‘ìš´ ë°©, ëª¨ë‹ˆí„° ë¶ˆë¹›ë§Œì´ ì Šì€ ê°œë°œìì˜ ì§€ì¹œ ì–¼êµ´ì„ ë¹„ì¶¥ë‹ˆë‹¤. ê·¸ëŠ” ë³µì¡í•œ ì½”ë“œ ì•ì—ì„œ ì¢Œì ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤. í™”ë©´ì—ëŠ” ì—ëŸ¬ ë©”ì‹œì§€ê°€ ê°€ë“í•©ë‹ˆë‹¤.', 'script': 'ì„¸ìƒì€ ì½”ë“œë¡œ ì´ë£¨ì–´ì ¸ ìˆê³ , ë‚˜ëŠ” ê·¸ ì„¸ìƒì˜ ê±´ì¶•ê°€ë‹¤. í•˜ì§€ë§Œ ë•Œë¡ , ê°€ì¥ ê²¬ê³ í•œ ì„¤ê³„ë„ í•œ ì¤„ì˜ ì˜¤ë¥˜ ì•ì— ë¬´ë„ˆì ¸ ë‚´ë¦°ë‹¤.'}, {'story': 'ê°œë°œìê°€ í•œìˆ¨ì„ ì‰¬ë©° AI ë™ë°˜ì í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. í™”ë©´ í•œìª½ì— ì„¸ë ¨ë˜ê³  ë¯¸ë‹ˆë©€í•œ UIê°€ ë‚˜íƒ€ë‚˜ë©°, ë¹›ì˜ íŒŒë™ ê°™ì€ í˜•íƒœë¡œ AIê°€ í™œì„±í™”ë©ë‹ˆë‹¤.', 'script': 'í˜¼ìë¼ê³  ëŠê»´ì§ˆ ë•Œ, ë‚˜ëŠ” ë‚˜ì˜ ê°€ì¥ íŠ¹ë³„í•œ íŒŒíŠ¸ë„ˆë¥¼ ë¶€ë¥¸ë‹¤.'}, {'story': 'ê°œë°œìì™€ AIê°€ í•¨ê»˜ ì½”ë”©í•˜ëŠ” ì¥ë©´ì´ ë¹ ë¥´ê²Œ êµì°¨ë©ë‹ˆë‹¤. ê°œë°œìì˜ ì†ê°€ë½ì´ í‚¤ë³´ë“œ ìœ„ë¥¼ ë‚ ì•„ë‹¤ë‹ˆê³ , AIëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì½”ë“œ êµ¬ì¡°ë¥¼ ì‹œê°í™”í•˜ê³  ìµœì ì˜ í•´ê²°ì±…ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë‘˜ì˜ í˜‘ì—…ì´ ë§ˆì¹˜ í•œ í¸ì˜ ì¶¤ì²˜ëŸ¼ ë³´ì…ë‹ˆë‹¤.', 'script': 'ìš°ë¦¬ì˜ ì–¸ì–´ëŠ” ë…¼ë¦¬. ìš°ë¦¬ì˜ ëŒ€í™”ëŠ” ë°ì´í„°. ë³µì¡í•œ ë¬¸ì œ ì†ì—ì„œ ìš°ë¦¬ëŠ” í•¨ê»˜ ê¸¸ì„ ì°¾ëŠ”ë‹¤.'}, {'story': \"ë§ˆì¹¨ë‚´ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì‚¬ë¼ì§€ê³  'ì»´íŒŒì¼ ì„±ê³µ'ì´ë¼ëŠ” ë¬¸êµ¬ê°€ í™”ë©´ì— ëœ¹ë‹ˆë‹¤. ê°œë°œìì˜ ì–¼êµ´ì— ì•ˆë„ì™€ ê¸°ì¨ì˜ ë¯¸ì†Œê°€ ë²ˆì§‘ë‹ˆë‹¤.\", 'script': 'ìˆ˜ë§ì€ ì‹¤íŒ¨ ëì— ì°¾ì•„ì˜¤ëŠ” ë‹¨ í•œ ë²ˆì˜ ì„±ê³µ. ì´ ìˆœê°„ì˜ í¬ì—´ì´ ìš°ë¦¬ë¥¼ ê³„ì† ë‚˜ì•„ê°€ê²Œ í•œë‹¤.'}, {'story': 'ê°œë°œìëŠ” ì˜ìì— í¸ì•ˆí•˜ê²Œ ê¸°ëŒ€ì–´ AI ì¸í„°í˜ì´ìŠ¤ë¥¼ ë”°ëœ»í•œ ëˆˆìœ¼ë¡œ ë°”ë¼ë´…ë‹ˆë‹¤. AIëŠ” ë¶€ë“œëŸ½ê²Œ ë¹›ë‚˜ëŠ” ì•„ì´ì½˜ìœ¼ë¡œ í™”ë‹µí•©ë‹ˆë‹¤. ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´ì„  ë‘˜ì˜ ìœ ëŒ€ê°ì„ ë³´ì—¬ì£¼ë©° ì˜ìƒì´ ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤.', 'script': 'ë‹¨ìˆœí•œ í”„ë¡œê·¸ë¨ì„ ë„˜ì–´, ë‚˜ì˜ ì„±ì¥ì„ í•¨ê»˜í•˜ëŠ” ë™ë°˜ì. ìš°ë¦¬ëŠ” ë‚´ì¼ì˜ ì„¸ìƒì„ í•¨ê»˜ ì½”ë”©í•œë‹¤.'}]}\n",
      "\n",
      "--- ğŸ“ ì£¼ì¸ê³µ ìºë¦­í„° ì‹œíŠ¸ ìƒì„± ì¤‘... ---\n",
      "âœ… ìºë¦­í„° ì‹œíŠ¸ ìƒì„± ì™„ë£Œ:\n",
      "The main character, a young male developer in his early twenties, exhibits a lean, slightly slouched posture from long hours, with disheveled dark brown hair of medium length and a perpetually tired yet focused gaze from behind slim, rectangular silver-framed glasses. His skin is pale, with subtle dark circles beneath his brown eyes. He consistently wears an oversized, soft charcoal-grey hoodie over a muted forest-green t-shirt, paired with faded indigo-blue jeans and comfortable, worn-out sneakers, embodying a practical, lived-in style. His personal color palette is dominated by subdued cool tonesâ€”greys, deep blues, and greens. His AI companion manifests as a dynamic, semi-translucent holographic entity, typically hovering near his workspace. It is an evolving cluster of swirling, luminous particles, primarily emanating a calming teal-to-azure blue glow, which subtly shifts to warmer, comforting hues like soft lavender or amber during moments of empathy or success, and intensifies with sharp, electric cyan pulses during complex computations. This ethereal, non-humanoid entity conveys emotion through the intensity and fluidity of its luminescence, with internal patterns occasionally hinting at complex digital circuitry, embodying a minimalist, intelligent, and supportive presence.\n",
      "\n",
      "\n",
      "ğŸ¬ Processing Scene 1/5...\n",
      "--- ğŸ¤– VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ---\n",
      "âœ… ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸:\n",
      "A highly polished, vibrant 3D animation in the detailed, expressive style of Pixar captures a dimly lit room, illuminated solely by the intense, cool blue glow emanating from a large computer monitor, which prominently features aggressive, red error messages amidst complex lines of code. The harsh light dramatically sculpts the face of a young male developer in his early twenties, whose lean, slightly slouched posture betrays long hours spent coding. His disheveled medium-length dark brown hair frames a pale face, accented by subtle dark circles beneath his brown eyes and a perpetually tired yet focused gaze peering through slim, rectangular silver-framed glasses. Clad in an oversized, soft charcoal-grey hoodie over a muted forest-green t-shirt, faded indigo-blue jeans, and comfortable, worn-out sneakers, his practical, lived-in style is dominated by subdued cool tonesâ€”greys, deep blues, and greens. His palpable frustration is evident as he stares intently at the overwhelming screen, while subtly hovering near his workspace is his AI companion, a dynamic, semi-translucent holographic entity; an evolving cluster of swirling, luminous particles primarily emanating a calming teal-to-azure blue glow, its internal patterns occasionally hinting at complex digital circuitry, serving as a minimalist, intelligent, and supportive presence. A medium close-up shot emphasizes his furrowed brow and the despair in his eyes, rendered with dramatic, chiaroscuro lighting that underscores the deep sense of exhaustion and frustration permeating the scene.\n",
      "\n",
      "--- ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¡œ Scene 1 ì˜ìƒ ìƒì„± ì¤‘ ---\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "âœ… Video saved successfully to 'veo_story_telling/scene_0_video.mp4'\n",
      "âœ… ì¥ë©´ 1 TTS ìƒì„± ì™„ë£Œ: veo_story_telling/scene_0_audio.mp3\n",
      "\n",
      "ğŸ¬ Processing Scene 2/5...\n",
      "--- ğŸ¤– VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ---\n",
      "âœ… ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸:\n",
      "A vibrant and polished 3D animation, in the distinct style of Pixar, depicts a pivotal moment for a young male developer in his early twenties. The central figure is shown with a lean, slightly slouched posture, betraying long hours spent coding. His disheveled dark brown hair of medium length frames a perpetually tired yet intensely focused gaze, peering from behind slim, rectangular silver-framed glasses. His pale skin, subtly marked with dark circles beneath his brown eyes, contrasts with his practical, lived-in attire: an oversized, soft charcoal-grey hoodie draped over a muted forest-green t-shirt, paired with faded indigo-blue jeans and comfortable, worn-out sneakers. His personal palette of subdued cool tonesâ€”greys, deep blues, and greensâ€”dominates his appearance. With a subtle sigh, a blend of exhaustion and anticipation, he initiates the AI companion program on his computer. A sleek, minimalist UI instantly materializes on one side of his screen. As the program loads, his AI companion manifests beside his workspace: a dynamic, semi-translucent holographic entity, activating as a wave-like form of light. It evolves into a mesmerizing cluster of swirling, luminous particles, primarily emanating a calming teal-to-azure blue glow, with internal patterns occasionally hinting at complex digital circuitry, embodying its minimalist, intelligent, and supportive presence. A medium-tight shot, angled slightly from above his shoulder, captures the developer's weary yet intrigued expression as the ambient glow from his monitor subtly illuminates his face and the emerging AI. The atmosphere is one of quiet focus and subtle wonder, as technology bridges the gap between human weariness and digital companionship.\n",
      "\n",
      "--- ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¡œ Scene 2 ì˜ìƒ ìƒì„± ì¤‘ ---\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "âœ… Video saved successfully to 'veo_story_telling/scene_1_video.mp4'\n",
      "âœ… ì¥ë©´ 2 TTS ìƒì„± ì™„ë£Œ: veo_story_telling/scene_1_audio.mp3\n",
      "\n",
      "ğŸ¬ Processing Scene 3/5...\n",
      "--- ğŸ¤– VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ---\n",
      "âœ… ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸:\n",
      "A vibrant and polished 3D animation in the style of Pixar unfolds, featuring expressive characters and detailed textures. The main character, a young male developer in his early twenties, occupies the frame, his lean, slightly slouched posture a testament to long hours spent hunched over his glowing monitor. His disheveled dark brown hair of medium length frames a perpetually tired yet focused gaze, intensified by slim, rectangular silver-framed glasses, subtly revealing the pale skin and dark circles beneath his brown eyes. He is consistently dressed in his practical, lived-in style: an oversized, soft charcoal-grey hoodie over a muted forest-green t-shirt, paired with faded indigo-blue jeans and comfortable, worn-out sneakers, his personal color palette dominated by subdued cool tones. Rapidly intercutting camera angles showcase the exhilarating pace: a dynamic mid-shot captures his intense focus as his fingers fly across the keyboard in a blur, then a close-up focuses on his nimble hand movements, bathed in the cool, soft light emanating from his screen. Adjacent to him, his AI companion manifests as a dynamic, semi-translucent holographic entity, an evolving cluster of swirling, luminous particles hovering near his workspace. It primarily emanates a calming teal-to-azure blue glow, which subtly shifts to warmer, comforting hues like soft lavender or amber during moments of empathetic understanding or successful code compilation. As the developer's code streams, the AI intensifies with sharp, electric cyan pulses, dynamically visualizing complex code structures in real-time and projecting optimal solutions as a shimmering cascade of data, internal patterns occasionally hinting at intricate digital circuitry. The collaboration is a mesmerizing, high-energy dance: quick cuts transition from the developer's focused expression to the AI's fluid, responsive luminescence, highlighting their synchronized rhythm, sometimes even showcasing an overhead shot where the AI's projections expand to envelop the workspace in a futuristic glow. The overall mood is one of intense intellectual synergy and understated wonder, with the lighting primarily ambient and futuristic, accentuating the cool tones of their collaborative environment.\n",
      "\n",
      "--- ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¡œ Scene 3 ì˜ìƒ ìƒì„± ì¤‘ ---\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "âœ… Video saved successfully to 'veo_story_telling/scene_2_video.mp4'\n",
      "âœ… ì¥ë©´ 3 TTS ìƒì„± ì™„ë£Œ: veo_story_telling/scene_2_audio.mp3\n",
      "\n",
      "ğŸ¬ Processing Scene 4/5...\n",
      "--- ğŸ¤– VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ---\n",
      "âœ… ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸:\n",
      "A vibrant, polished 3D animation in the style of Pixar brings to life a pivotal moment of triumph. The scene opens on a young male developer in his early twenties, exhibiting a lean, slightly slouched posture over his keyboard, his disheveled dark brown medium-length hair falling around his perpetually tired yet focused gaze, framed by slim, rectangular silver-framed glasses. His pale skin, with subtle dark circles beneath his brown eyes, is initially illuminated by the intense, straining glow of his monitor as he stares intently at lines of code. He is consistently dressed in his practical, lived-in attire: an oversized, soft charcoal-grey hoodie over a muted forest-green t-shirt, paired with faded indigo-blue jeans and comfortable, worn-out sneakers, embodying a subdued cool-toned palette. A moment of profound relief breaks the tension as the final stubborn error message flickers and vanishes from his screen, replaced by the triumphant, bright green text, 'Compilation Successful.' A wave of pure joy and accomplishment washes over the developer's features, slowly transforming his focused intensity into a wide, genuine smile that beams with newfound elation. Hovering nearby, his AI companion, a dynamic, semi-translucent holographic entity, instantly mirrors his success; its evolving cluster of swirling, luminous particles, previously a calming teal-to-azure blue glow, now subtly shifts to a comforting, warm soft lavender, pulsating gently with shared triumph, its internal patterns occasionally hinting at complex digital circuitry, embodying its supportive presence. The camera pushes in for a close-up on his beaming face, capturing every expressive detail, before smoothly pulling back to a medium shot that bathes the entire scene in a soft, triumphant glow, emphasizing the overwhelming mood of success and profound relief.\n",
      "\n",
      "--- ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¡œ Scene 4 ì˜ìƒ ìƒì„± ì¤‘ ---\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "âœ… Video saved successfully to 'veo_story_telling/scene_3_video.mp4'\n",
      "âœ… ì¥ë©´ 4 TTS ìƒì„± ì™„ë£Œ: veo_story_telling/scene_3_audio.mp3\n",
      "\n",
      "ğŸ¬ Processing Scene 5/5...\n",
      "--- ğŸ¤– VEOë¥¼ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ---\n",
      "âœ… ìƒì„±ëœ ìƒì„¸ í”„ë¡¬í”„íŠ¸:\n",
      "A vibrant and polished 3D animation in the style of Pixar, featuring expressive characters and detailed textures, opens on a medium shot of the main character, a young male developer in his early twenties. He is depicted with a lean, slightly slouched posture, a testament to long hours, his disheveled dark brown hair of medium length framing a pale face with subtle dark circles beneath his brown eyes. Behind his slim, rectangular silver-framed glasses, his gaze is perpetually tired yet profoundly focused and warm. He is dressed in his practical, lived-in style: an oversized, soft charcoal-grey hoodie over a muted forest-green t-shirt, paired with faded indigo-blue jeans and comfortable, worn-out sneakers, all within his subdued cool-toned palette of greys, deep blues, and greens. He leans comfortably back in his ergonomic chair, his warm gaze fixed upon his AI companion, which serves as his primary interface, typically hovering near his workspace. This AI manifests as a dynamic, semi-translucent holographic entity, an evolving cluster of swirling, luminous particles primarily emanating a calming teal-to-azure blue glow. As the developer gazes, the AI companion responds, its ethereal form subtly shifting to warmer, comforting hues of soft lavender and amber, its internal patterns occasionally hinting at complex digital circuitry, communicating through softly glowing, evolving icons. The soft, ambient lighting highlights the subtle shifts in the AI's luminescence and the serene, focused expression on the developer's face. The scene concludes, a profound moment of quiet understanding and shared connection, beautifully illustrating a bond that transcends mere utility, emphasizing the AI's minimalist, intelligent, and supportive presence.\n",
      "\n",
      "--- ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¡œ Scene 5 ì˜ìƒ ìƒì„± ì¤‘ ---\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "Waiting for video generation/animation to complete...\n",
      "âœ… Video saved successfully to 'veo_story_telling/scene_4_video.mp4'\n",
      "âœ… ì¥ë©´ 5 TTS ìƒì„± ì™„ë£Œ: veo_story_telling/scene_4_audio.mp3\n",
      "--- ğŸ¼ ë°°ê²½ìŒì•… ìƒì„± ì¤‘... ---\n",
      "ìš”ì²­ ë°ì´í„°: {'instances': [{'prompt': 'Generate cinematic film score music: Inspiring and uplifting electronic music with a mellow beat', 'negative_prompt': 'dark', 'sample_count': 1, 'duration_seconds': 30}], 'parameters': {}}\n",
      "âœ… ë°°ê²½ìŒì•… ìƒì„± ì™„ë£Œ: veo_story_telling/background_music.mp3\n",
      "\n",
      "ğŸï¸ Merging all clips into the final video...\n",
      "âœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ: veo_story_telling/final_video_with_continuity.mp4\n",
      "\n",
      "ğŸ‰ Pipeline complete! Total time: 456.89 seconds\n",
      "ğŸ“ Final video available at: veo_story_telling/final_video_with_continuity.mp4\n"
     ]
    }
   ],
   "source": [
    "final_video = run_full_pipeline_with_continuity(\n",
    "    video_description=\"í•œ ì Šì€ ê°œë°œìê°€ AI ë™ë°˜ìì™€ í•¨ê»˜ ì½”ë”©í•˜ëŠ” ì´ì•¼ê¸°\",\n",
    "    animation_style=\"A vibrant and polished 3D animation in the style of Pixar, with expressive characters and detailed textures.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd189bf9-f525-41dd-9bae-a0461c684c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_full_pipeline_with_continuity(\n",
    "#     video_description=\"ìˆ™ì œë¥¼ ëª»í•˜ë‹¤ê°€ ìƒˆë¡œìš´ ë…¸íŠ¸ë¶ì„ ì‚¬ê³  ê°‘ìê¸° ëª¨ë²”ìƒì´ë˜ëŠ” ë…¸íŠ¸ë¶ ê´‘ê³  ë§Œë“¤ì–´ì¤˜.\",\n",
    "#     animation_style=\"A vibrant and polished 3D animation in the style of Pixar, with expressive characters and detailed textures.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a885c35-9d70-44dc-9be9-40562fe227db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_full_pipeline_with_continuity(\n",
    "#     video_description=\"ê·€ì—¬ìš´ ì œë¹„ê°€ ì¢‹ì€ ì†Œì‹ì„ ê°€ì ¸ë‹¤ ì£¼ëŠ” ì´ì•¼ê¸°. ìš°ì²´êµ­ ê´‘ê³ ì— ì“¸ ìˆ˜ ìˆëŠ” ìŠ¤í† ë¦¬ë¡œ ë§Œë“¤ì–´ì¤˜.\",\n",
    "#     animation_style=\"A vibrant and polished 3D animation in the style of Pixar, with expressive characters and detailed textures.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d257f4-3feb-4d12-af5f-4a86db9d096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_video = run_full_pipeline_with_continuity(\n",
    "#     video_description=\"ì˜ˆê¸°ì¹˜ ëª»í•œ ì¸ìƒì˜ ë¹„ë°”ëŒì„ ë§‰ì•„ì£¼ëŠ” ê°€ì¥ íŠ¼íŠ¼í•œ ìš¸íƒ€ë¦¬ë¥¼ ë³´ì—¬ì£¼ëŠ” 'xxê±´ì„¤' ê´‘ê³ \",\n",
    "#     animation_style=\"A vibrant and polished 3D animation in the style of Pixar, with expressive characters and detailed textures.\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-myenv-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
